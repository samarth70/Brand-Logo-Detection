{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Brand logo detection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "uIul3ikNrAZg",
        "ctLk_ZhdJLcE",
        "rAwDmuQQ7ONl",
        "RUAhlP_hdDd1",
        "_1aOiHGIzaqr",
        "5i-2wY5xRy_S",
        "XvCOUUw1Rrw2",
        "4zZzkvULsXGx"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XuGRqwEiCzH"
      },
      "source": [
        "#BRAND LOGO DETECTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx5vD4rhiCmv"
      },
      "source": [
        "##IMPORTING LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Hv2FyOmkId0"
      },
      "source": [
        "%%capture\n",
        "!pip install tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JvxhXCwhqNK"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1LzAnYxm-f-"
      },
      "source": [
        "BATCH_SIZE = 8\n",
        "HEIGHT,WIDTH = 224,224\n",
        "CHANNELS = 3\n",
        "NUM_CLASSES =6 \n",
        "SEED = 143"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e2T25xNr34W"
      },
      "source": [
        "##LOADING DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzYt-LIKiZGu"
      },
      "source": [
        "\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "def download(flid,path,unzp=False):\n",
        "  return gdd.download_file_from_google_drive(file_id=flid,\n",
        "                                    dest_path=path,\n",
        "                                    unzip=unzp)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_-dZRtxEU73"
      },
      "source": [
        "##Download the video file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUFuvTuz-bFy",
        "outputId": "6f53e532-80db-4f01-e0b0-0e4bf3f861d7"
      },
      "source": [
        "# https://drive.google.com/file/d/1z1_Bgthqy2RaU8Yvdcscqul4DbQdoAFD/view?usp=sharing\n",
        "# https://drive.google.com/file/d/1KwK5YdfaYJQT9CINhLa8g9oQtZawUCOP/view?usp=sharing\n",
        "# https://drive.google.com/file/d/13gX_hg3903OKBviXVur5i7VycOlW-0nW/view?usp=sharing\n",
        "\n",
        "download('13gX_hg3903OKBviXVur5i7VycOlW-0nW','./content/test_video/test_vid.mp4',False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 13gX_hg3903OKBviXVur5i7VycOlW-0nW into ./content/test_video/test_vid.mp4... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIul3ikNrAZg"
      },
      "source": [
        "##VIDEO TO FRAMES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgiARASRrFJ7"
      },
      "source": [
        "import cv2\n",
        "\n",
        "\n",
        "def vid_to_frames(video_path):\n",
        "    \n",
        "  # Read the video from specified path\n",
        "  cam = cv2.VideoCapture(video_path)\n",
        "    #../content/content/test_vid.mp4 \n",
        "  try:\n",
        "        \n",
        "      # creating a folder named data\n",
        "      if not os.path.exists('test/test_data'):\n",
        "          os.makedirs('test/test_data')\n",
        "\n",
        "    \n",
        "  # if not created then raise error\n",
        "  except OSError:\n",
        "      print ('Error: Creating directory of data')\n",
        "    \n",
        "  \n",
        "  currentframe = 0\n",
        "  os.chdir('/content/test/test_data')  \n",
        "  while(True):\n",
        "        \n",
        "      \n",
        "      ret,frame = cam.read()\n",
        "    \n",
        "      if ret:\n",
        "          \n",
        "          name = '../test_data/frame' + str(currentframe) + '.jpg'\n",
        "          cv2.imwrite(name, frame)\n",
        "          currentframe += 1\n",
        "      else:\n",
        "          break\n",
        "  cam.release()\n",
        "  cv2.destroyAllWindows()\n",
        "  %cd /content/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qRsv5TLIy8f"
      },
      "source": [
        "vid_to_frames('../content/content/test_video/test_vid.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9n4p4QUI7b1",
        "outputId": "5e7faa35-063c-4bb6-a3b6-cb3f9687a507"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctLk_ZhdJLcE"
      },
      "source": [
        "### local test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq-TWsf3CILq",
        "outputId": "b96c6d57-3551-4a41-d3f5-56b46f9ddfc3"
      },
      "source": [
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=50,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range = 0.2, \n",
        "    zoom_range = 0.2,\n",
        "   )\n",
        "my_test = test_datagen.flow_from_directory(\n",
        "                             '/content/test',\n",
        "                             target_size = (HEIGHT,WIDTH),\n",
        "                             batch_size = BATCH_SIZE,\n",
        "                             class_mode = \"categorical\",\n",
        "                             shuffle = False,\n",
        "                             seed = SEED,\n",
        "                            #  classes=CLASSES,\n",
        "                             color_mode='rgb'\n",
        "                            )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1500 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx59cNahCII8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-flECGmCrFE9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VerhvvDy0rs"
      },
      "source": [
        "##TRAIN DATASET PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjdxiIx2vWFM",
        "outputId": "4c91eac9-5172-422e-9b7f-00b932e2ee0b"
      },
      "source": [
        "gdd.download_file_from_google_drive(file_id='1f0UrrqcAMyZk4WjQFt7l1W0z_O0-LTqt',\n",
        "                                    dest_path='./content/brands.zip',\n",
        "                                    unzip=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1f0UrrqcAMyZk4WjQFt7l1W0z_O0-LTqt into ./content/brands.zip... Done.\n",
            "Unzipping...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYLYrCAAl8U5"
      },
      "source": [
        "TRAIN_PATH = \"../content/content/logos3/train\"\n",
        "TEST_PATH = \"../content/content/logos3/test\"\n",
        "\n",
        "\n",
        "CLASSES=['Burger King','KFC','McDonalds','Other','Starbucks','Subway']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sffL058YGSIA"
      },
      "source": [
        "from tensorflow.keras.applications.densenet import preprocess_input "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12SU0NISu5oY",
        "outputId": "0e6bf2cd-e78f-43e5-93a0-d8d58ae2a632"
      },
      "source": [
        "#Data generated\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    horizontal_flip=True,\n",
        "    # width_shift_range=0.2,\n",
        "    # height_shift_range=0.2,\n",
        "    shear_range = 0.2, \n",
        "    zoom_range = 0.21,\n",
        "    validation_split=0.12,  \n",
        "    preprocessing_function= tf.keras.applications.nasnet.preprocess_input \n",
        "   )\n",
        "\n",
        "#Data stored in train & test \n",
        "train_ds = train_datagen.flow_from_directory(\n",
        "                             TRAIN_PATH,\n",
        "                             target_size = (HEIGHT,WIDTH),\n",
        "                             batch_size = BATCH_SIZE,\n",
        "                             class_mode = \"categorical\",\n",
        "                             shuffle = True,\n",
        "                             seed = SEED,\n",
        "                             classes=CLASSES,\n",
        "                             subset = \"training\",\n",
        "                             color_mode='rgb'\n",
        "                            )\n",
        "val_ds = train_datagen.flow_from_directory(\n",
        "                             TRAIN_PATH,\n",
        "                             target_size = (HEIGHT,WIDTH),\n",
        "                             batch_size = BATCH_SIZE,\n",
        "                             class_mode = \"categorical\",\n",
        "                             shuffle = False,\n",
        "                             seed = SEED,\n",
        "                             classes=CLASSES,\n",
        "                             subset = \"validation\",\n",
        "                             color_mode='rgb'\n",
        "                            )\n",
        "\n",
        "\n",
        "classes_dict = train_ds.class_indices\n",
        "# classes_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1533 images belonging to 6 classes.\n",
            "Found 205 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNAtqiqpyqYR"
      },
      "source": [
        "##TEST DATASET PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl8ANYtOv-Pq",
        "outputId": "8bf5f216-50e1-46ac-9b2f-83b86d102519"
      },
      "source": [
        "\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    horizontal_flip=True,\n",
        "    # width_shift_range=0.2,\n",
        "    # height_shift_range=0.2,\n",
        "    shear_range = 0.2, \n",
        "    zoom_range = 0.2,\n",
        "    preprocessing_function=tf.keras.applications.nasnet.preprocess_input \n",
        "   )\n",
        "test_ds = test_datagen.flow_from_directory(\n",
        "                             TEST_PATH,\n",
        "                             target_size = (HEIGHT,WIDTH),\n",
        "                             batch_size = BATCH_SIZE,\n",
        "                             class_mode = \"categorical\",\n",
        "                             shuffle = False,\n",
        "                             seed = SEED,\n",
        "                             classes=CLASSES,\n",
        "                             color_mode='rgb'\n",
        "                            )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 560 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAwDmuQQ7ONl"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDThk8cG7UlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c2934fa-1698-4b2e-c826-7457f7af267e"
      },
      "source": [
        "def create_model7():\n",
        "    model = tf.keras.applications.VGG16(weights= \"imagenet\",\n",
        "                                    include_top=False,\n",
        "                                    input_shape=(HEIGHT,WIDTH,CHANNELS), pooling=\"avg\")\n",
        "    predictions = tf.keras.layers.Dense(32, activation='relu', name='predictions')(model.output)\n",
        "    model = tf.keras.Model(inputs=model.input, outputs=predictions)\n",
        "    \n",
        "    \n",
        "    model = tf.keras.Model(model.input, model.layers[-2].output)\n",
        "    \n",
        "    x = tf.keras.layers.Dense(512, activation = \"relu\")(model.output)\n",
        "    x = tf.keras.layers.Dropout(0.1)(x)\n",
        "    x = tf.keras.layers.Dense(256, activation = \"relu\")(x)\n",
        "    x = tf.keras.layers.Dropout(0.1)(x)\n",
        "    x = tf.keras.layers.Dense(128, activation = \"relu\")(x)\n",
        "    # x = tf.keras.layers.Dropout(0.1)(x)\n",
        "    x = tf.keras.layers.Dense(64, activation = \"relu\")(x)\n",
        "    outputs = tf.keras.layers.Dense(6, activation = \"softmax\", dtype = tf.float32)(x)\n",
        "    model = tf.keras.Model(model.input,outputs)\n",
        "    \n",
        "    for layer in model.layers[:-10]:\n",
        "        layer.trainble = False\n",
        "    return model\n",
        "\n",
        "\n",
        "model=create_model7()  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUAhlP_hdDd1"
      },
      "source": [
        "## InceptionResNetV2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhv3bj2pdDeN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32cd8fe2-bbc3-4077-ec81-3058ba28a33b"
      },
      "source": [
        "\n",
        "def create_model8():\n",
        "    model = tf.keras.applications.InceptionResNetV2(weights= \"imagenet\",\n",
        "                                    include_top=False,\n",
        "                                    input_shape=(HEIGHT,WIDTH,CHANNELS), pooling=\"avg\")\n",
        "    predictions = tf.keras.layers.Dense(32, activation='relu', name='predictions')(model.output)\n",
        "    model = tf.keras.Model(inputs=model.input, outputs=predictions)\n",
        "    \n",
        "    \n",
        "    model = tf.keras.Model(model.input, model.layers[-2].output)\n",
        "    \n",
        "    x = tf.keras.layers.Dense(512, activation = \"relu\")(model.output)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(256, activation = \"relu\")(x)\n",
        "    # x = tf.keras.layers.Dropout(0.1)(x)\n",
        "    x = tf.keras.layers.Dense(128, activation = \"relu\")(x)\n",
        "    # x = tf.keras.layers.Dropout(0.1)(x)\n",
        "    x = tf.keras.layers.Dense(64, activation = \"relu\")(x)\n",
        "    outputs = tf.keras.layers.Dense(6, activation = \"softmax\", dtype = tf.float32)(x)\n",
        "    model = tf.keras.Model(model.input,outputs)\n",
        "    \n",
        "    for layer in model.layers[:-2]:\n",
        "        layer.trainble = False\n",
        "    return model\n",
        "\n",
        "\n",
        "model=create_model8()  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 7s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdShe5g-eGMK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1aOiHGIzaqr"
      },
      "source": [
        "## BASE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqmnF_t1VgyE"
      },
      "source": [
        "\n",
        "IMAGE_SIZE=(224,224)\n",
        "def conv_block(filters, inputs):\n",
        "    x = tf.keras.layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
        "    x = tf.keras.layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    outputs = tf.keras.layers.MaxPool2D()(x)\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def dense_block(units, dropout_rate, inputs):\n",
        "    x = tf.keras.layers.Dense(units, activation=\"relu\")(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    outputs = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    return outputs\n",
        "def build_model():\n",
        "    inputs = tf.keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "    x = tf.keras.layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs)\n",
        "    x = tf.keras.layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = tf.keras.layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = tf.keras.layers.MaxPool2D()(x)\n",
        "\n",
        "    x = conv_block(32, x)\n",
        "    x = conv_block(64, x)\n",
        "\n",
        "    x = conv_block(128, x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = conv_block(256, x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = dense_block(512, 0.7, x)\n",
        "    x = dense_block(128, 0.5, x)\n",
        "    x = dense_block(64, 0.3, x)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "   \n",
        "def create_model():\n",
        "    model=build_model()\n",
        "    model = tf.keras.Model(model.input, model.layers[-2].output)\n",
        "    outputs = tf.keras.layers.Dense(NUM_CLASSES,activation = \"softmax\", name = \"output\")(model.output)\n",
        "    \n",
        "    model = tf.keras.Model(model.input, outputs)\n",
        "    return model\n",
        "\n",
        "model=create_model()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_NgStf3zfFT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMKhhOJJJkD-"
      },
      "source": [
        "##MOBILENET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sncvkhe3JjaZ"
      },
      "source": [
        "\n",
        "def create_model3():\n",
        "    model = tf.keras.applications.MobileNetV2(weights= \"imagenet\",\n",
        "                                                     include_top=False,\n",
        "                                                     input_shape=(HEIGHT,WIDTH,CHANNELS))\n",
        "    predictions = tf.keras.layers.Dense(32, activation='sigmoid', name='predictions')(model.output)\n",
        "    model = tf.keras.Model(inputs=model.input, outputs=predictions)\n",
        "\n",
        "    model = tf.keras.Model(model.input, model.layers[-2].output)\n",
        "    \n",
        "    x = tf.keras.layers.Dense(512, activation = \"relu\")(model.output)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "    x = tf.keras.layers.Dense(256, activation = \"relu\")(x)\n",
        "    # x = tf.keras.layers.Dense(128, activation = \"relu\")(x)\n",
        "    # x = tf.keras.layers.Dense(64, activation = \"relu\")(x)\n",
        "    outputs = tf.keras.layers.Dense(6, activation = \"softmax\", dtype = tf.float32)(x)\n",
        "    model = tf.keras.Model(model.input,outputs)\n",
        "    \n",
        "    # for layer in model.layers[:-14]:\n",
        "    #     layer.trainble = False\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# model2 = create_model3()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5i-2wY5xRy_S"
      },
      "source": [
        "## CUSTOM KERAS MODEL "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2021-04-24T18:15:37.984599Z",
          "iopub.status.busy": "2021-04-24T18:15:37.984002Z",
          "iopub.status.idle": "2021-04-24T18:15:37.986702Z",
          "shell.execute_reply": "2021-04-24T18:15:37.987154Z"
        },
        "papermill": {
          "duration": 0.038846,
          "end_time": "2021-04-24T18:15:37.987278",
          "exception": false,
          "start_time": "2021-04-24T18:15:37.948432",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sought-tongue",
        "outputId": "96e33df5-4f20-41f7-e146-59722d9733d7"
      },
      "source": [
        "\n",
        "IMAGE_SIZE=(224,224)\n",
        "def conv_block(filters, inputs):\n",
        "    x = tf.keras.layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
        "    x = tf.keras.layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    outputs = tf.keras.layers.MaxPool2D()(x)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def dense_block(units, dropout_rate, inputs):\n",
        "    x = tf.keras.layers.Dense(units, activation=\"relu\")(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    outputs = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    return outputs\n",
        "def build_model():\n",
        "    inputs = tf.keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "    x = tf.keras.layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs)\n",
        "    x = tf.keras.layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = tf.keras.layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = tf.keras.layers.MaxPool2D()(x)\n",
        "\n",
        "    x = conv_block(32, x)\n",
        "    x = conv_block(64, x)\n",
        "\n",
        "    x = conv_block(128, x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = conv_block(256, x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = dense_block(512, 0.7, x)\n",
        "    x = dense_block(128, 0.5, x)\n",
        "    x = dense_block(64, 0.3, x)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "   \n",
        "def create_model2():\n",
        "    model=build_model()\n",
        "    # model = tf.keras.models.load_model(\"../input/pneumonia-classification-challenge/xray_model.h5\")\n",
        "    model = tf.keras.Model(model.input, model.layers[-2].output)\n",
        "    outputs = tf.keras.layers.Dense(6,activation = \"softmax\", name = \"output\")(model.output)\n",
        "    \n",
        "    model = tf.keras.Model(model.input, outputs)\n",
        "    return model\n",
        "tf.keras.applications.DenseNet121\n",
        "print(\"Keras Model\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keras Model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvCOUUw1Rrw2"
      },
      "source": [
        "## DENSENET121"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2021-04-24T18:15:38.062426Z",
          "iopub.status.busy": "2021-04-24T18:15:38.061912Z",
          "iopub.status.idle": "2021-04-24T18:15:44.914994Z",
          "shell.execute_reply": "2021-04-24T18:15:44.914533Z"
        },
        "papermill": {
          "duration": 6.896319,
          "end_time": "2021-04-24T18:15:44.915144",
          "exception": false,
          "start_time": "2021-04-24T18:15:38.018825",
          "status": "completed"
        },
        "tags": [],
        "id": "personal-corporation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d8997c-4ec4-49f1-8585-7460c57e33f4"
      },
      "source": [
        "#best_score\n",
        "def create_model():\n",
        "    model = tf.keras.applications.DenseNet121(weights= \"imagenet\",\n",
        "                                    include_top=False,\n",
        "                                    input_shape=(HEIGHT,WIDTH,CHANNELS), pooling=\"avg\")\n",
        "    predictions = tf.keras.layers.Dense(32, activation='sigmoid', name='predictions')(model.output)\n",
        "    model = tf.keras.Model(inputs=model.input, outputs=predictions)\n",
        "    \n",
        "    # model.load_weights(\"../content/best_model.h5\")\n",
        "    model = tf.keras.Model(model.input, model.layers[-2].output)\n",
        "    \n",
        "    x = tf.keras.layers.Dense(512, activation = \"relu\")(model.output)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    x = tf.keras.layers.Dense(256, activation = \"relu\")(x)\n",
        "    # x = tf.keras.layers.Dropout(0.1)(x)\n",
        "    x = tf.keras.layers.Dense(128, activation = \"relu\")(x)\n",
        "    x = tf.keras.layers.Dense(64, activation = \"relu\")(x)\n",
        "    x = tf.keras.layers.Dense(64, activation = \"relu\")(x)\n",
        "    outputs = tf.keras.layers.Dense(6, activation = \"softmax\", dtype = tf.float32)(x)\n",
        "    model = tf.keras.Model(model.input,outputs)\n",
        "    \n",
        "    for layer in model.layers[:-14]:\n",
        "        layer.trainble = False\n",
        "    return model\n",
        "\n",
        "model = create_model()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 0s 0us/step\n",
            "29097984/29084464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfPQIl9847P5"
      },
      "source": [
        "##LOADING SAVED MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbnE80xdoskP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85f20c4d-7e4d-443a-d933-5459a4f68767"
      },
      "source": [
        "# https://drive.google.com/file/d/15rxX48a0qJaEwiFbGQ6PLMX3pr5hdEak/view?usp=sharing\n",
        "# https://drive.google.com/file/d/1FItPjTndNgunasm0FWCFQDr3qJ1WfHf6/view?usp=sharing\n",
        "# https://drive.google.com/file/d/10vxQ7afAJresvSZh5EPCGQ6-4JWK3CZm/view?usp=sharing\n",
        "# 1aVuN4xVwiPazCxH3KK4sW14y6HS6lAK5\n",
        "\n",
        "download(flid='10vxQ7afAJresvSZh5EPCGQ6-4JWK3CZm',\n",
        "         path='/content/saved_model/best_model_74.h5'\n",
        "         )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 10vxQ7afAJresvSZh5EPCGQ6-4JWK3CZm into /content/saved_model/best_model_74.h5... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecbf75j6pbOD"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model=load_model('/content/saved_model/best_model_74.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxJDMtPQpdhm"
      },
      "source": [
        "##COMPILING MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-24T18:15:44.987944Z",
          "iopub.status.busy": "2021-04-24T18:15:44.987417Z",
          "iopub.status.idle": "2021-04-24T18:15:44.990652Z",
          "shell.execute_reply": "2021-04-24T18:15:44.991499Z"
        },
        "papermill": {
          "duration": 0.042823,
          "end_time": "2021-04-24T18:15:44.991635",
          "exception": false,
          "start_time": "2021-04-24T18:15:44.948812",
          "status": "completed"
        },
        "tags": [],
        "id": "fifteen-pillow"
      },
      "source": [
        "def compile_model(model, lr):\n",
        "    \n",
        "    optimizer =tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "        \n",
        "    loss = \"categorical_crossentropy\"\n",
        "    \n",
        "    metrics = [\n",
        "       tfa.metrics.F1Score(num_classes = NUM_CLASSES,average = \"macro\", name = \"f1_score\"),\n",
        "       tf.keras.metrics.CategoricalAccuracy(name='acc')\n",
        "    ]\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-24T18:15:45.067732Z",
          "iopub.status.busy": "2021-04-24T18:15:45.066201Z",
          "iopub.status.idle": "2021-04-24T18:15:45.068570Z",
          "shell.execute_reply": "2021-04-24T18:15:45.068973Z"
        },
        "papermill": {
          "duration": 0.043367,
          "end_time": "2021-04-24T18:15:45.069121",
          "exception": false,
          "start_time": "2021-04-24T18:15:45.025754",
          "status": "completed"
        },
        "tags": [],
        "id": "arbitrary-lotus"
      },
      "source": [
        "import datetime, os\n",
        "%reload_ext tensorboard\n",
        "\n",
        "METRIC = \"val_f1_score\"\n",
        "\n",
        "def create_callbacks(metric = METRIC): \n",
        "    \n",
        "    cpk_path = './best_model.h5'\n",
        "    \n",
        "    #Saving model checkpoints\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=cpk_path,\n",
        "        monitor= metric,\n",
        "        mode='max',\n",
        "        save_best_only=True,\n",
        "        verbose=1,\n",
        "    )\n",
        "\n",
        "    \n",
        "    logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "    # Reducing learning rate\n",
        "    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor= metric,\n",
        "        mode='max',\n",
        "        factor=0.1,\n",
        "        patience=1,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    earlystop = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor= metric,\n",
        "        mode='max',\n",
        "        patience=10, \n",
        "        verbose=1\n",
        "    )\n",
        "    \n",
        "    callbacks = [checkpoint, reducelr, earlystop,tensorboard_callback]         \n",
        "    \n",
        "    return callbacks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aD8B2C4aPzk"
      },
      "source": [
        "## MODEL EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-24T18:15:45.141964Z",
          "iopub.status.busy": "2021-04-24T18:15:45.141455Z",
          "iopub.status.idle": "2021-04-24T18:39:18.317038Z",
          "shell.execute_reply": "2021-04-24T18:39:18.316375Z"
        },
        "papermill": {
          "duration": 1413.214156,
          "end_time": "2021-04-24T18:39:18.317223",
          "exception": false,
          "start_time": "2021-04-24T18:15:45.103067",
          "status": "completed"
        },
        "tags": [],
        "id": "municipal-synthesis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3e64acc-898f-4adb-dd15-967e5860b861"
      },
      "source": [
        "EPOCHS= 10\n",
        "VERBOSE =1\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  \n",
        "  \n",
        "  model = compile_model(model, lr=0.0001)\n",
        "\n",
        "  callbacks = create_callbacks()\n",
        "\n",
        "  history = model.fit(train_ds, \n",
        "                      epochs=EPOCHS,\n",
        "                      callbacks=callbacks,\n",
        "                      validation_data = val_ds,\n",
        "                        verbose=VERBOSE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "192/192 [==============================] - 74s 304ms/step - loss: 0.8948 - f1_score: 0.4443 - acc: 0.6895 - val_loss: 2.0432 - val_f1_score: 0.1086 - val_acc: 0.4829\n",
            "\n",
            "Epoch 00001: val_f1_score improved from -inf to 0.10855, saving model to ./best_model.h5\n",
            "Epoch 2/10\n",
            "192/192 [==============================] - 52s 271ms/step - loss: 0.2399 - f1_score: 0.8635 - acc: 0.9302 - val_loss: 3.7153 - val_f1_score: 0.0985 - val_acc: 0.2293\n",
            "\n",
            "Epoch 00002: val_f1_score did not improve from 0.10855\n",
            "\n",
            "Epoch 00002: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 3/10\n",
            "192/192 [==============================] - 52s 272ms/step - loss: 0.1383 - f1_score: 0.9541 - acc: 0.9687 - val_loss: 1.8661 - val_f1_score: 0.2604 - val_acc: 0.5854\n",
            "\n",
            "Epoch 00003: val_f1_score improved from 0.10855 to 0.26041, saving model to ./best_model.h5\n",
            "Epoch 4/10\n",
            "192/192 [==============================] - 52s 271ms/step - loss: 0.0876 - f1_score: 0.9704 - acc: 0.9804 - val_loss: 0.6633 - val_f1_score: 0.6037 - val_acc: 0.8000\n",
            "\n",
            "Epoch 00004: val_f1_score improved from 0.26041 to 0.60368, saving model to ./best_model.h5\n",
            "Epoch 5/10\n",
            "192/192 [==============================] - 52s 271ms/step - loss: 0.0820 - f1_score: 0.9587 - acc: 0.9759 - val_loss: 0.2219 - val_f1_score: 0.8870 - val_acc: 0.9317\n",
            "\n",
            "Epoch 00005: val_f1_score improved from 0.60368 to 0.88704, saving model to ./best_model.h5\n",
            "Epoch 6/10\n",
            "192/192 [==============================] - 52s 271ms/step - loss: 0.0601 - f1_score: 0.9796 - acc: 0.9863 - val_loss: 0.1469 - val_f1_score: 0.9450 - val_acc: 0.9610\n",
            "\n",
            "Epoch 00006: val_f1_score improved from 0.88704 to 0.94504, saving model to ./best_model.h5\n",
            "Epoch 7/10\n",
            "192/192 [==============================] - 52s 271ms/step - loss: 0.0573 - f1_score: 0.9794 - acc: 0.9850 - val_loss: 0.1010 - val_f1_score: 0.9457 - val_acc: 0.9707\n",
            "\n",
            "Epoch 00007: val_f1_score improved from 0.94504 to 0.94567, saving model to ./best_model.h5\n",
            "Epoch 8/10\n",
            "192/192 [==============================] - 52s 272ms/step - loss: 0.0412 - f1_score: 0.9918 - acc: 0.9935 - val_loss: 0.0954 - val_f1_score: 0.9815 - val_acc: 0.9854\n",
            "\n",
            "Epoch 00008: val_f1_score improved from 0.94567 to 0.98149, saving model to ./best_model.h5\n",
            "Epoch 9/10\n",
            "192/192 [==============================] - 52s 272ms/step - loss: 0.0532 - f1_score: 0.9843 - acc: 0.9876 - val_loss: 0.0919 - val_f1_score: 0.9707 - val_acc: 0.9707\n",
            "\n",
            "Epoch 00009: val_f1_score did not improve from 0.98149\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "Epoch 10/10\n",
            "192/192 [==============================] - 52s 272ms/step - loss: 0.0668 - f1_score: 0.9784 - acc: 0.9830 - val_loss: 0.1007 - val_f1_score: 0.9792 - val_acc: 0.9756\n",
            "\n",
            "Epoch 00010: val_f1_score did not improve from 0.98149\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c93gumHHqlUU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJTO59MDCl45"
      },
      "source": [
        "## Test data from Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGd2XvTnChLs"
      },
      "source": [
        "\n",
        "pred = model.predict(my_test)\n",
        "labels = (train_ds.class_indices)\n",
        "predicted_class_indices=np.argmax(pred,axis=1)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "\n",
        "predictedLables= [labels[k] for k in predicted_class_indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI_T37g8CyXz"
      },
      "source": [
        "\n",
        "results=pd.DataFrame(predictedLables)\n",
        "results.to_csv(\"results.txt\",index=False,header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zZzkvULsXGx"
      },
      "source": [
        "##PREDICTING TEST DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it02zVZOqHKC"
      },
      "source": [
        "pred = model.predict(test_ds)\n",
        "labels = (train_ds.class_indices)\n",
        "predicted_class_indices=np.argmax(pred,axis=1)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "\n",
        "predictedLables= [labels[k] for k in predicted_class_indices]\n",
        "\n",
        "actualLables= [labels[k] for k in test_ds.classes]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YJJeQZJti3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc1a3f76-f6c6-4bdc-c18a-44175426cc51"
      },
      "source": [
        "accuracy_score(actualLables,predictedLables)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7214285714285714"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7sC_qbj3hhv"
      },
      "source": [
        "filenames=test_ds.filenames\n",
        "\n",
        "directory= test_ds.directory\n",
        "results=pd.DataFrame({\"Actual\": actualLables,\n",
        "                      \"Predictions\":predictedLables,\n",
        "                      \"Directory\":directory\n",
        "                      })\n",
        "# results=pd.DataFrame(predictedLables)\n",
        "results.to_csv(\"results.txt\",index=False,header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiTVVqFPFcae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "606f1f13-b30d-4eb0-af15-b58a4f9c9331"
      },
      "source": [
        "results.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predictions</th>\n",
              "      <th>Directory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Burger King</td>\n",
              "      <td>Burger King</td>\n",
              "      <td>../content/content/logos3/test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Burger King</td>\n",
              "      <td>Burger King</td>\n",
              "      <td>../content/content/logos3/test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Burger King</td>\n",
              "      <td>Burger King</td>\n",
              "      <td>../content/content/logos3/test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Burger King</td>\n",
              "      <td>Burger King</td>\n",
              "      <td>../content/content/logos3/test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Burger King</td>\n",
              "      <td>Burger King</td>\n",
              "      <td>../content/content/logos3/test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Actual  Predictions                       Directory\n",
              "0  Burger King  Burger King  ../content/content/logos3/test\n",
              "1  Burger King  Burger King  ../content/content/logos3/test\n",
              "2  Burger King  Burger King  ../content/content/logos3/test\n",
              "3  Burger King  Burger King  ../content/content/logos3/test\n",
              "4  Burger King  Burger King  ../content/content/logos3/test"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGKr05RmN4eB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}